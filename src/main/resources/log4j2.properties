# src/main/resources/log4j2.properties
status = error
name = SparkLog4j2

# === Appender console ===
appender.console.type = Console
appender.console.name = Console
appender.console.target = SYSTEM_OUT
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{HH:mm:ss} %-5p %c{1.} - %m%n

# === Racine ===
rootLogger.level = WARN
rootLogger.appenderRefs = console
rootLogger.appenderRef.console.ref = Console

# === Couper le bruit verbeux par sous-logger ===
# Spark (général)
logger.spark.name  = org.apache.spark
logger.spark.level = WARN
logger.spark.additivity = false

# Planification / exécutions
logger.scheduler.name  = org.apache.spark.scheduler
logger.scheduler.level = ERROR
logger.scheduler.additivity = false

logger.storage.name  = org.apache.spark.storage
logger.storage.level = ERROR
logger.storage.additivity = false

logger.exec.name  = org.apache.spark.executor
logger.exec.level = WARN
logger.exec.additivity = false

# SQL / physical planning (DataSourceStrategy, FileSourceStrategy, FileScanRDD, CodeGenerator?)
logger.sqlexec.name  = org.apache.spark.sql.execution
logger.sqlexec.level = ERROR
logger.sqlexec.additivity = false

logger.catalyst.name  = org.apache.spark.sql.catalyst
logger.catalyst.level = ERROR
logger.catalyst.additivity = false

# Delta Lake (les messages "PrepareDeltaScan: DELTA: Filtering files for query")
logger.deltaSpark.name  = org.apache.spark.sql.delta
logger.deltaSpark.level = WARN
logger.deltaSpark.additivity = false

logger.deltaIo.name  = io.delta
logger.deltaIo.level = WARN
logger.deltaIo.additivity = false

# Parquet / Hadoop
logger.parquet.name  = org.apache.parquet
logger.parquet.level = ERROR
logger.parquet.additivity = false

logger.hadoop.name  = org.apache.hadoop
logger.hadoop.level = WARN
logger.hadoop.additivity = false

# Jetty et autres paquets "org.sparkproject" (web UI, HTTP)
logger.sparkproject.name  = org.sparkproject
logger.sparkproject.level = WARN
logger.sparkproject.additivity = false


